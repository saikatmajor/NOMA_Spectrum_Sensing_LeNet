{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a5c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f3f6fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b7fe3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 200\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 28*28\n",
    "NUM_CLASSES = 2\n",
    "NUM_CHANNELS = 2\n",
    "\n",
    "# Other\n",
    "DEVICE = \"cuda:0\"\n",
    "GRAYSCALE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6be4566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_contents = sio.loadmat('noma_downlink_2state_data.mat') \n",
    "CC = mat_contents['CC']\n",
    "N = CC.shape[0]\n",
    "theta = mat_contents['theta'].reshape(N)\n",
    "x = torch.tensor(CC).float()\n",
    "y = torch.tensor(theta).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "018290de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.8, shuffle=True)\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "186c3a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([64, 2, 28, 28])\n",
      "Image label dimensions: torch.Size([64])\n",
      "Image batch dimensions: torch.Size([64, 2, 28, 28])\n",
      "Image label dimensions: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True)\n",
    "# Checking the dataset\n",
    "for features, labels in train_loader:  \n",
    "    print('Image batch dimensions:', features.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break\n",
    "\n",
    "# Checking the dataset\n",
    "for features, labels in train_loader:  \n",
    "    print('Image batch dimensions:', features.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96635914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c7430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, num_channels):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        in_channels = num_channels\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 6*in_channels, kernel_size=5, padding=2),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(6*in_channels, 16*in_channels, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*5*5*in_channels, 120*in_channels),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(120*in_channels, 84*in_channels),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(84*in_channels, num_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3bdd023",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = LeNet5(NUM_CLASSES, NUM_CHANNELS)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec468bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "       layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ef54508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb50ff6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/200 | Batch 0000/0063 | Cost: 0.6900\n",
      "Epoch: 001/200 | Batch 0050/0063 | Cost: 0.6708\n",
      "Epoch: 001/200 | Train: 76.100%\n",
      "Time elapsed: 0.10 min\n",
      "Epoch: 002/200 | Batch 0000/0063 | Cost: 0.6567\n",
      "Epoch: 002/200 | Batch 0050/0063 | Cost: 0.4597\n",
      "Epoch: 002/200 | Train: 97.425%\n",
      "Time elapsed: 0.11 min\n",
      "Epoch: 003/200 | Batch 0000/0063 | Cost: 0.3689\n",
      "Epoch: 003/200 | Batch 0050/0063 | Cost: 0.1290\n",
      "Epoch: 003/200 | Train: 98.775%\n",
      "Time elapsed: 0.12 min\n",
      "Epoch: 004/200 | Batch 0000/0063 | Cost: 0.0899\n",
      "Epoch: 004/200 | Batch 0050/0063 | Cost: 0.0743\n",
      "Epoch: 004/200 | Train: 98.975%\n",
      "Time elapsed: 0.12 min\n",
      "Epoch: 005/200 | Batch 0000/0063 | Cost: 0.0315\n",
      "Epoch: 005/200 | Batch 0050/0063 | Cost: 0.0172\n",
      "Epoch: 005/200 | Train: 99.150%\n",
      "Time elapsed: 0.13 min\n",
      "Epoch: 006/200 | Batch 0000/0063 | Cost: 0.0468\n",
      "Epoch: 006/200 | Batch 0050/0063 | Cost: 0.0086\n",
      "Epoch: 006/200 | Train: 99.625%\n",
      "Time elapsed: 0.13 min\n",
      "Epoch: 007/200 | Batch 0000/0063 | Cost: 0.0182\n",
      "Epoch: 007/200 | Batch 0050/0063 | Cost: 0.0166\n",
      "Epoch: 007/200 | Train: 98.850%\n",
      "Time elapsed: 0.14 min\n",
      "Epoch: 008/200 | Batch 0000/0063 | Cost: 0.0589\n",
      "Epoch: 008/200 | Batch 0050/0063 | Cost: 0.0197\n",
      "Epoch: 008/200 | Train: 99.300%\n",
      "Time elapsed: 0.15 min\n",
      "Epoch: 009/200 | Batch 0000/0063 | Cost: 0.0480\n",
      "Epoch: 009/200 | Batch 0050/0063 | Cost: 0.0341\n",
      "Epoch: 009/200 | Train: 99.675%\n",
      "Time elapsed: 0.15 min\n",
      "Epoch: 010/200 | Batch 0000/0063 | Cost: 0.0125\n",
      "Epoch: 010/200 | Batch 0050/0063 | Cost: 0.0222\n",
      "Epoch: 010/200 | Train: 99.975%\n",
      "Time elapsed: 0.16 min\n",
      "Epoch: 011/200 | Batch 0000/0063 | Cost: 0.0066\n",
      "Epoch: 011/200 | Batch 0050/0063 | Cost: 0.0008\n",
      "Epoch: 011/200 | Train: 99.925%\n",
      "Time elapsed: 0.16 min\n",
      "Epoch: 012/200 | Batch 0000/0063 | Cost: 0.0131\n",
      "Epoch: 012/200 | Batch 0050/0063 | Cost: 0.0036\n",
      "Epoch: 012/200 | Train: 100.000%\n",
      "Time elapsed: 0.17 min\n",
      "Epoch: 013/200 | Batch 0000/0063 | Cost: 0.0010\n",
      "Epoch: 013/200 | Batch 0050/0063 | Cost: 0.0008\n",
      "Epoch: 013/200 | Train: 100.000%\n",
      "Time elapsed: 0.18 min\n",
      "Epoch: 014/200 | Batch 0000/0063 | Cost: 0.0010\n",
      "Epoch: 014/200 | Batch 0050/0063 | Cost: 0.0025\n",
      "Epoch: 014/200 | Train: 99.975%\n",
      "Time elapsed: 0.18 min\n",
      "Epoch: 015/200 | Batch 0000/0063 | Cost: 0.0032\n",
      "Epoch: 015/200 | Batch 0050/0063 | Cost: 0.0003\n",
      "Epoch: 015/200 | Train: 100.000%\n",
      "Time elapsed: 0.19 min\n",
      "Epoch: 016/200 | Batch 0000/0063 | Cost: 0.0096\n",
      "Epoch: 016/200 | Batch 0050/0063 | Cost: 0.0054\n",
      "Epoch: 016/200 | Train: 100.000%\n",
      "Time elapsed: 0.19 min\n",
      "Epoch: 017/200 | Batch 0000/0063 | Cost: 0.0030\n",
      "Epoch: 017/200 | Batch 0050/0063 | Cost: 0.0025\n",
      "Epoch: 017/200 | Train: 100.000%\n",
      "Time elapsed: 0.20 min\n",
      "Epoch: 018/200 | Batch 0000/0063 | Cost: 0.0012\n",
      "Epoch: 018/200 | Batch 0050/0063 | Cost: 0.0051\n",
      "Epoch: 018/200 | Train: 100.000%\n",
      "Time elapsed: 0.20 min\n",
      "Epoch: 019/200 | Batch 0000/0063 | Cost: 0.0006\n",
      "Epoch: 019/200 | Batch 0050/0063 | Cost: 0.0014\n",
      "Epoch: 019/200 | Train: 100.000%\n",
      "Time elapsed: 0.21 min\n",
      "Epoch: 020/200 | Batch 0000/0063 | Cost: 0.0011\n",
      "Epoch: 020/200 | Batch 0050/0063 | Cost: 0.0021\n",
      "Epoch: 020/200 | Train: 100.000%\n",
      "Time elapsed: 0.22 min\n",
      "Epoch: 021/200 | Batch 0000/0063 | Cost: 0.0002\n",
      "Epoch: 021/200 | Batch 0050/0063 | Cost: 0.0009\n",
      "Epoch: 021/200 | Train: 100.000%\n",
      "Time elapsed: 0.22 min\n",
      "Epoch: 022/200 | Batch 0000/0063 | Cost: 0.0018\n",
      "Epoch: 022/200 | Batch 0050/0063 | Cost: 0.0006\n",
      "Epoch: 022/200 | Train: 100.000%\n",
      "Time elapsed: 0.23 min\n",
      "Epoch: 023/200 | Batch 0000/0063 | Cost: 0.0016\n",
      "Epoch: 023/200 | Batch 0050/0063 | Cost: 0.0003\n",
      "Epoch: 023/200 | Train: 100.000%\n",
      "Time elapsed: 0.23 min\n",
      "Epoch: 024/200 | Batch 0000/0063 | Cost: 0.0002\n",
      "Epoch: 024/200 | Batch 0050/0063 | Cost: 0.0004\n",
      "Epoch: 024/200 | Train: 100.000%\n",
      "Time elapsed: 0.24 min\n",
      "Epoch: 025/200 | Batch 0000/0063 | Cost: 0.0003\n",
      "Epoch: 025/200 | Batch 0050/0063 | Cost: 0.0011\n",
      "Epoch: 025/200 | Train: 100.000%\n",
      "Time elapsed: 0.25 min\n",
      "Epoch: 026/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 026/200 | Batch 0050/0063 | Cost: 0.0001\n",
      "Epoch: 026/200 | Train: 100.000%\n",
      "Time elapsed: 0.25 min\n",
      "Epoch: 027/200 | Batch 0000/0063 | Cost: 0.0003\n",
      "Epoch: 027/200 | Batch 0050/0063 | Cost: 0.0015\n",
      "Epoch: 027/200 | Train: 100.000%\n",
      "Time elapsed: 0.26 min\n",
      "Epoch: 028/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 028/200 | Batch 0050/0063 | Cost: 0.0002\n",
      "Epoch: 028/200 | Train: 100.000%\n",
      "Time elapsed: 0.26 min\n",
      "Epoch: 029/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 029/200 | Batch 0050/0063 | Cost: 0.0007\n",
      "Epoch: 029/200 | Train: 100.000%\n",
      "Time elapsed: 0.27 min\n",
      "Epoch: 030/200 | Batch 0000/0063 | Cost: 0.0006\n",
      "Epoch: 030/200 | Batch 0050/0063 | Cost: 0.0003\n",
      "Epoch: 030/200 | Train: 100.000%\n",
      "Time elapsed: 0.27 min\n",
      "Epoch: 031/200 | Batch 0000/0063 | Cost: 0.0009\n",
      "Epoch: 031/200 | Batch 0050/0063 | Cost: 0.0004\n",
      "Epoch: 031/200 | Train: 100.000%\n",
      "Time elapsed: 0.28 min\n",
      "Epoch: 032/200 | Batch 0000/0063 | Cost: 0.0005\n",
      "Epoch: 032/200 | Batch 0050/0063 | Cost: 0.0003\n",
      "Epoch: 032/200 | Train: 100.000%\n",
      "Time elapsed: 0.29 min\n",
      "Epoch: 033/200 | Batch 0000/0063 | Cost: 0.0006\n",
      "Epoch: 033/200 | Batch 0050/0063 | Cost: 0.0001\n",
      "Epoch: 033/200 | Train: 100.000%\n",
      "Time elapsed: 0.29 min\n",
      "Epoch: 034/200 | Batch 0000/0063 | Cost: 0.0003\n",
      "Epoch: 034/200 | Batch 0050/0063 | Cost: 0.0002\n",
      "Epoch: 034/200 | Train: 100.000%\n",
      "Time elapsed: 0.30 min\n",
      "Epoch: 035/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 035/200 | Batch 0050/0063 | Cost: 0.0003\n",
      "Epoch: 035/200 | Train: 100.000%\n",
      "Time elapsed: 0.30 min\n",
      "Epoch: 036/200 | Batch 0000/0063 | Cost: 0.0002\n",
      "Epoch: 036/200 | Batch 0050/0063 | Cost: 0.0001\n",
      "Epoch: 036/200 | Train: 100.000%\n",
      "Time elapsed: 0.31 min\n",
      "Epoch: 037/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 037/200 | Batch 0050/0063 | Cost: 0.0005\n",
      "Epoch: 037/200 | Train: 100.000%\n",
      "Time elapsed: 0.32 min\n",
      "Epoch: 038/200 | Batch 0000/0063 | Cost: 0.0004\n",
      "Epoch: 038/200 | Batch 0050/0063 | Cost: 0.0006\n",
      "Epoch: 038/200 | Train: 100.000%\n",
      "Time elapsed: 0.32 min\n",
      "Epoch: 039/200 | Batch 0000/0063 | Cost: 0.0002\n",
      "Epoch: 039/200 | Batch 0050/0063 | Cost: 0.0001\n",
      "Epoch: 039/200 | Train: 100.000%\n",
      "Time elapsed: 0.33 min\n",
      "Epoch: 040/200 | Batch 0000/0063 | Cost: 0.0004\n",
      "Epoch: 040/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 040/200 | Train: 100.000%\n",
      "Time elapsed: 0.33 min\n",
      "Epoch: 041/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 041/200 | Batch 0050/0063 | Cost: 0.0004\n",
      "Epoch: 041/200 | Train: 100.000%\n",
      "Time elapsed: 0.34 min\n",
      "Epoch: 042/200 | Batch 0000/0063 | Cost: 0.0002\n",
      "Epoch: 042/200 | Batch 0050/0063 | Cost: 0.0002\n",
      "Epoch: 042/200 | Train: 100.000%\n",
      "Time elapsed: 0.35 min\n",
      "Epoch: 043/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 043/200 | Batch 0050/0063 | Cost: 0.0003\n",
      "Epoch: 043/200 | Train: 100.000%\n",
      "Time elapsed: 0.35 min\n",
      "Epoch: 044/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 044/200 | Batch 0050/0063 | Cost: 0.0002\n",
      "Epoch: 044/200 | Train: 100.000%\n",
      "Time elapsed: 0.36 min\n",
      "Epoch: 045/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 045/200 | Batch 0050/0063 | Cost: 0.0001\n",
      "Epoch: 045/200 | Train: 100.000%\n",
      "Time elapsed: 0.36 min\n",
      "Epoch: 046/200 | Batch 0000/0063 | Cost: 0.0004\n",
      "Epoch: 046/200 | Batch 0050/0063 | Cost: 0.0002\n",
      "Epoch: 046/200 | Train: 100.000%\n",
      "Time elapsed: 0.37 min\n",
      "Epoch: 047/200 | Batch 0000/0063 | Cost: 0.0002\n",
      "Epoch: 047/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 047/200 | Train: 100.000%\n",
      "Time elapsed: 0.37 min\n",
      "Epoch: 048/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 048/200 | Batch 0050/0063 | Cost: 0.0001\n",
      "Epoch: 048/200 | Train: 100.000%\n",
      "Time elapsed: 0.38 min\n",
      "Epoch: 049/200 | Batch 0000/0063 | Cost: 0.0002\n",
      "Epoch: 049/200 | Batch 0050/0063 | Cost: 0.0003\n",
      "Epoch: 049/200 | Train: 100.000%\n",
      "Time elapsed: 0.39 min\n",
      "Epoch: 050/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 050/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 050/200 | Train: 100.000%\n",
      "Time elapsed: 0.39 min\n",
      "Epoch: 051/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 051/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 051/200 | Train: 100.000%\n",
      "Time elapsed: 0.40 min\n",
      "Epoch: 052/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 052/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 052/200 | Train: 100.000%\n",
      "Time elapsed: 0.40 min\n",
      "Epoch: 053/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 053/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 053/200 | Train: 100.000%\n",
      "Time elapsed: 0.41 min\n",
      "Epoch: 054/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 054/200 | Batch 0050/0063 | Cost: 0.0001\n",
      "Epoch: 054/200 | Train: 100.000%\n",
      "Time elapsed: 0.42 min\n",
      "Epoch: 055/200 | Batch 0000/0063 | Cost: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 055/200 | Batch 0050/0063 | Cost: 0.0001\n",
      "Epoch: 055/200 | Train: 100.000%\n",
      "Time elapsed: 0.42 min\n",
      "Epoch: 056/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 056/200 | Batch 0050/0063 | Cost: 0.0001\n",
      "Epoch: 056/200 | Train: 100.000%\n",
      "Time elapsed: 0.43 min\n",
      "Epoch: 057/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 057/200 | Batch 0050/0063 | Cost: 0.0001\n",
      "Epoch: 057/200 | Train: 100.000%\n",
      "Time elapsed: 0.43 min\n",
      "Epoch: 058/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 058/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 058/200 | Train: 100.000%\n",
      "Time elapsed: 0.44 min\n",
      "Epoch: 059/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 059/200 | Batch 0050/0063 | Cost: 0.0001\n",
      "Epoch: 059/200 | Train: 100.000%\n",
      "Time elapsed: 0.44 min\n",
      "Epoch: 060/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 060/200 | Batch 0050/0063 | Cost: 0.0002\n",
      "Epoch: 060/200 | Train: 100.000%\n",
      "Time elapsed: 0.45 min\n",
      "Epoch: 061/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 061/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 061/200 | Train: 100.000%\n",
      "Time elapsed: 0.46 min\n",
      "Epoch: 062/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 062/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 062/200 | Train: 100.000%\n",
      "Time elapsed: 0.46 min\n",
      "Epoch: 063/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 063/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 063/200 | Train: 100.000%\n",
      "Time elapsed: 0.47 min\n",
      "Epoch: 064/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 064/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 064/200 | Train: 100.000%\n",
      "Time elapsed: 0.47 min\n",
      "Epoch: 065/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 065/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 065/200 | Train: 100.000%\n",
      "Time elapsed: 0.48 min\n",
      "Epoch: 066/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 066/200 | Batch 0050/0063 | Cost: 0.0001\n",
      "Epoch: 066/200 | Train: 100.000%\n",
      "Time elapsed: 0.49 min\n",
      "Epoch: 067/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 067/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 067/200 | Train: 100.000%\n",
      "Time elapsed: 0.49 min\n",
      "Epoch: 068/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 068/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 068/200 | Train: 100.000%\n",
      "Time elapsed: 0.50 min\n",
      "Epoch: 069/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 069/200 | Batch 0050/0063 | Cost: 0.0001\n",
      "Epoch: 069/200 | Train: 100.000%\n",
      "Time elapsed: 0.50 min\n",
      "Epoch: 070/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 070/200 | Batch 0050/0063 | Cost: 0.0001\n",
      "Epoch: 070/200 | Train: 100.000%\n",
      "Time elapsed: 0.51 min\n",
      "Epoch: 071/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 071/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 071/200 | Train: 100.000%\n",
      "Time elapsed: 0.51 min\n",
      "Epoch: 072/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 072/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 072/200 | Train: 100.000%\n",
      "Time elapsed: 0.52 min\n",
      "Epoch: 073/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 073/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 073/200 | Train: 100.000%\n",
      "Time elapsed: 0.53 min\n",
      "Epoch: 074/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 074/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 074/200 | Train: 100.000%\n",
      "Time elapsed: 0.53 min\n",
      "Epoch: 075/200 | Batch 0000/0063 | Cost: 0.0001\n",
      "Epoch: 075/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 075/200 | Train: 100.000%\n",
      "Time elapsed: 0.54 min\n",
      "Epoch: 076/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 076/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 076/200 | Train: 100.000%\n",
      "Time elapsed: 0.54 min\n",
      "Epoch: 077/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 077/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 077/200 | Train: 100.000%\n",
      "Time elapsed: 0.55 min\n",
      "Epoch: 078/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 078/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 078/200 | Train: 100.000%\n",
      "Time elapsed: 0.56 min\n",
      "Epoch: 079/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 079/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 079/200 | Train: 100.000%\n",
      "Time elapsed: 0.56 min\n",
      "Epoch: 080/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 080/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 080/200 | Train: 100.000%\n",
      "Time elapsed: 0.57 min\n",
      "Epoch: 081/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 081/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 081/200 | Train: 100.000%\n",
      "Time elapsed: 0.57 min\n",
      "Epoch: 082/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 082/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 082/200 | Train: 100.000%\n",
      "Time elapsed: 0.58 min\n",
      "Epoch: 083/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 083/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 083/200 | Train: 100.000%\n",
      "Time elapsed: 0.58 min\n",
      "Epoch: 084/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 084/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 084/200 | Train: 100.000%\n",
      "Time elapsed: 0.59 min\n",
      "Epoch: 085/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 085/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 085/200 | Train: 100.000%\n",
      "Time elapsed: 0.60 min\n",
      "Epoch: 086/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 086/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 086/200 | Train: 100.000%\n",
      "Time elapsed: 0.60 min\n",
      "Epoch: 087/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 087/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 087/200 | Train: 100.000%\n",
      "Time elapsed: 0.61 min\n",
      "Epoch: 088/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 088/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 088/200 | Train: 100.000%\n",
      "Time elapsed: 0.61 min\n",
      "Epoch: 089/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 089/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 089/200 | Train: 100.000%\n",
      "Time elapsed: 0.62 min\n",
      "Epoch: 090/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 090/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 090/200 | Train: 100.000%\n",
      "Time elapsed: 0.63 min\n",
      "Epoch: 091/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 091/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 091/200 | Train: 100.000%\n",
      "Time elapsed: 0.63 min\n",
      "Epoch: 092/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 092/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 092/200 | Train: 100.000%\n",
      "Time elapsed: 0.64 min\n",
      "Epoch: 093/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 093/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 093/200 | Train: 100.000%\n",
      "Time elapsed: 0.64 min\n",
      "Epoch: 094/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 094/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 094/200 | Train: 100.000%\n",
      "Time elapsed: 0.65 min\n",
      "Epoch: 095/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 095/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 095/200 | Train: 100.000%\n",
      "Time elapsed: 0.65 min\n",
      "Epoch: 096/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 096/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 096/200 | Train: 100.000%\n",
      "Time elapsed: 0.66 min\n",
      "Epoch: 097/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 097/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 097/200 | Train: 100.000%\n",
      "Time elapsed: 0.67 min\n",
      "Epoch: 098/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 098/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 098/200 | Train: 100.000%\n",
      "Time elapsed: 0.67 min\n",
      "Epoch: 099/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 099/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 099/200 | Train: 100.000%\n",
      "Time elapsed: 0.68 min\n",
      "Epoch: 100/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 100/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 100/200 | Train: 100.000%\n",
      "Time elapsed: 0.68 min\n",
      "Epoch: 101/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 101/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 101/200 | Train: 100.000%\n",
      "Time elapsed: 0.69 min\n",
      "Epoch: 102/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 102/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 102/200 | Train: 100.000%\n",
      "Time elapsed: 0.69 min\n",
      "Epoch: 103/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 103/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 103/200 | Train: 100.000%\n",
      "Time elapsed: 0.70 min\n",
      "Epoch: 104/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 104/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 104/200 | Train: 100.000%\n",
      "Time elapsed: 0.71 min\n",
      "Epoch: 105/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 105/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 105/200 | Train: 100.000%\n",
      "Time elapsed: 0.71 min\n",
      "Epoch: 106/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 106/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 106/200 | Train: 100.000%\n",
      "Time elapsed: 0.72 min\n",
      "Epoch: 107/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 107/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 107/200 | Train: 100.000%\n",
      "Time elapsed: 0.72 min\n",
      "Epoch: 108/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 108/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 108/200 | Train: 100.000%\n",
      "Time elapsed: 0.73 min\n",
      "Epoch: 109/200 | Batch 0000/0063 | Cost: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 109/200 | Train: 100.000%\n",
      "Time elapsed: 0.74 min\n",
      "Epoch: 110/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 110/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 110/200 | Train: 100.000%\n",
      "Time elapsed: 0.74 min\n",
      "Epoch: 111/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 111/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 111/200 | Train: 100.000%\n",
      "Time elapsed: 0.75 min\n",
      "Epoch: 112/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 112/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 112/200 | Train: 100.000%\n",
      "Time elapsed: 0.75 min\n",
      "Epoch: 113/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 113/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 113/200 | Train: 100.000%\n",
      "Time elapsed: 0.76 min\n",
      "Epoch: 114/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 114/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 114/200 | Train: 100.000%\n",
      "Time elapsed: 0.76 min\n",
      "Epoch: 115/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 115/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 115/200 | Train: 100.000%\n",
      "Time elapsed: 0.77 min\n",
      "Epoch: 116/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 116/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 116/200 | Train: 100.000%\n",
      "Time elapsed: 0.78 min\n",
      "Epoch: 117/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 117/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 117/200 | Train: 100.000%\n",
      "Time elapsed: 0.78 min\n",
      "Epoch: 118/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 118/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 118/200 | Train: 100.000%\n",
      "Time elapsed: 0.79 min\n",
      "Epoch: 119/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 119/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 119/200 | Train: 100.000%\n",
      "Time elapsed: 0.79 min\n",
      "Epoch: 120/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 120/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 120/200 | Train: 100.000%\n",
      "Time elapsed: 0.80 min\n",
      "Epoch: 121/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 121/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 121/200 | Train: 100.000%\n",
      "Time elapsed: 0.81 min\n",
      "Epoch: 122/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 122/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 122/200 | Train: 100.000%\n",
      "Time elapsed: 0.81 min\n",
      "Epoch: 123/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 123/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 123/200 | Train: 100.000%\n",
      "Time elapsed: 0.82 min\n",
      "Epoch: 124/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 124/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 124/200 | Train: 100.000%\n",
      "Time elapsed: 0.82 min\n",
      "Epoch: 125/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 125/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 125/200 | Train: 100.000%\n",
      "Time elapsed: 0.83 min\n",
      "Epoch: 126/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 126/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 126/200 | Train: 100.000%\n",
      "Time elapsed: 0.83 min\n",
      "Epoch: 127/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 127/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 127/200 | Train: 100.000%\n",
      "Time elapsed: 0.84 min\n",
      "Epoch: 128/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 128/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 128/200 | Train: 100.000%\n",
      "Time elapsed: 0.85 min\n",
      "Epoch: 129/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 129/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 129/200 | Train: 100.000%\n",
      "Time elapsed: 0.85 min\n",
      "Epoch: 130/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 130/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 130/200 | Train: 100.000%\n",
      "Time elapsed: 0.86 min\n",
      "Epoch: 131/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 131/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 131/200 | Train: 100.000%\n",
      "Time elapsed: 0.86 min\n",
      "Epoch: 132/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 132/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 132/200 | Train: 100.000%\n",
      "Time elapsed: 0.87 min\n",
      "Epoch: 133/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 133/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 133/200 | Train: 100.000%\n",
      "Time elapsed: 0.88 min\n",
      "Epoch: 134/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 134/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 134/200 | Train: 100.000%\n",
      "Time elapsed: 0.88 min\n",
      "Epoch: 135/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 135/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 135/200 | Train: 100.000%\n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 136/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 136/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 136/200 | Train: 100.000%\n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 137/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 137/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 137/200 | Train: 100.000%\n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 138/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 138/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 138/200 | Train: 100.000%\n",
      "Time elapsed: 0.90 min\n",
      "Epoch: 139/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 139/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 139/200 | Train: 100.000%\n",
      "Time elapsed: 0.91 min\n",
      "Epoch: 140/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 140/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 140/200 | Train: 100.000%\n",
      "Time elapsed: 0.92 min\n",
      "Epoch: 141/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 141/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 141/200 | Train: 100.000%\n",
      "Time elapsed: 0.92 min\n",
      "Epoch: 142/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 142/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 142/200 | Train: 100.000%\n",
      "Time elapsed: 0.93 min\n",
      "Epoch: 143/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 143/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 143/200 | Train: 100.000%\n",
      "Time elapsed: 0.93 min\n",
      "Epoch: 144/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 144/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 144/200 | Train: 100.000%\n",
      "Time elapsed: 0.94 min\n",
      "Epoch: 145/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 145/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 145/200 | Train: 100.000%\n",
      "Time elapsed: 0.95 min\n",
      "Epoch: 146/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 146/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 146/200 | Train: 100.000%\n",
      "Time elapsed: 0.95 min\n",
      "Epoch: 147/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 147/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 147/200 | Train: 100.000%\n",
      "Time elapsed: 0.96 min\n",
      "Epoch: 148/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 148/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 148/200 | Train: 100.000%\n",
      "Time elapsed: 0.96 min\n",
      "Epoch: 149/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 149/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 149/200 | Train: 100.000%\n",
      "Time elapsed: 0.97 min\n",
      "Epoch: 150/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 150/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 150/200 | Train: 100.000%\n",
      "Time elapsed: 0.98 min\n",
      "Epoch: 151/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 151/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 151/200 | Train: 100.000%\n",
      "Time elapsed: 0.98 min\n",
      "Epoch: 152/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 152/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 152/200 | Train: 100.000%\n",
      "Time elapsed: 0.99 min\n",
      "Epoch: 153/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 153/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 153/200 | Train: 100.000%\n",
      "Time elapsed: 1.00 min\n",
      "Epoch: 154/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 154/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 154/200 | Train: 100.000%\n",
      "Time elapsed: 1.00 min\n",
      "Epoch: 155/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 155/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 155/200 | Train: 100.000%\n",
      "Time elapsed: 1.01 min\n",
      "Epoch: 156/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 156/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 156/200 | Train: 100.000%\n",
      "Time elapsed: 1.01 min\n",
      "Epoch: 157/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 157/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 157/200 | Train: 100.000%\n",
      "Time elapsed: 1.02 min\n",
      "Epoch: 158/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 158/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 158/200 | Train: 100.000%\n",
      "Time elapsed: 1.03 min\n",
      "Epoch: 159/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 159/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 159/200 | Train: 100.000%\n",
      "Time elapsed: 1.03 min\n",
      "Epoch: 160/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 160/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 160/200 | Train: 100.000%\n",
      "Time elapsed: 1.04 min\n",
      "Epoch: 161/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 161/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 161/200 | Train: 100.000%\n",
      "Time elapsed: 1.04 min\n",
      "Epoch: 162/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 162/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 162/200 | Train: 100.000%\n",
      "Time elapsed: 1.05 min\n",
      "Epoch: 163/200 | Batch 0000/0063 | Cost: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 163/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 163/200 | Train: 100.000%\n",
      "Time elapsed: 1.06 min\n",
      "Epoch: 164/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 164/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 164/200 | Train: 100.000%\n",
      "Time elapsed: 1.06 min\n",
      "Epoch: 165/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 165/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 165/200 | Train: 100.000%\n",
      "Time elapsed: 1.07 min\n",
      "Epoch: 166/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 166/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 166/200 | Train: 100.000%\n",
      "Time elapsed: 1.08 min\n",
      "Epoch: 167/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 167/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 167/200 | Train: 100.000%\n",
      "Time elapsed: 1.08 min\n",
      "Epoch: 168/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 168/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 168/200 | Train: 100.000%\n",
      "Time elapsed: 1.09 min\n",
      "Epoch: 169/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 169/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 169/200 | Train: 100.000%\n",
      "Time elapsed: 1.09 min\n",
      "Epoch: 170/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 170/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 170/200 | Train: 100.000%\n",
      "Time elapsed: 1.10 min\n",
      "Epoch: 171/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 171/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 171/200 | Train: 100.000%\n",
      "Time elapsed: 1.11 min\n",
      "Epoch: 172/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 172/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 172/200 | Train: 100.000%\n",
      "Time elapsed: 1.11 min\n",
      "Epoch: 173/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 173/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 173/200 | Train: 100.000%\n",
      "Time elapsed: 1.12 min\n",
      "Epoch: 174/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 174/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 174/200 | Train: 100.000%\n",
      "Time elapsed: 1.13 min\n",
      "Epoch: 175/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 175/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 175/200 | Train: 100.000%\n",
      "Time elapsed: 1.13 min\n",
      "Epoch: 176/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 176/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 176/200 | Train: 100.000%\n",
      "Time elapsed: 1.14 min\n",
      "Epoch: 177/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 177/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 177/200 | Train: 100.000%\n",
      "Time elapsed: 1.14 min\n",
      "Epoch: 178/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 178/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 178/200 | Train: 100.000%\n",
      "Time elapsed: 1.15 min\n",
      "Epoch: 179/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 179/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 179/200 | Train: 100.000%\n",
      "Time elapsed: 1.16 min\n",
      "Epoch: 180/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 180/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 180/200 | Train: 100.000%\n",
      "Time elapsed: 1.16 min\n",
      "Epoch: 181/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 181/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 181/200 | Train: 100.000%\n",
      "Time elapsed: 1.17 min\n",
      "Epoch: 182/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 182/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 182/200 | Train: 100.000%\n",
      "Time elapsed: 1.18 min\n",
      "Epoch: 183/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 183/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 183/200 | Train: 100.000%\n",
      "Time elapsed: 1.18 min\n",
      "Epoch: 184/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 184/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 184/200 | Train: 100.000%\n",
      "Time elapsed: 1.19 min\n",
      "Epoch: 185/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 185/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 185/200 | Train: 100.000%\n",
      "Time elapsed: 1.19 min\n",
      "Epoch: 186/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 186/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 186/200 | Train: 100.000%\n",
      "Time elapsed: 1.20 min\n",
      "Epoch: 187/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 187/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 187/200 | Train: 100.000%\n",
      "Time elapsed: 1.21 min\n",
      "Epoch: 188/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 188/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 188/200 | Train: 100.000%\n",
      "Time elapsed: 1.21 min\n",
      "Epoch: 189/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 189/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 189/200 | Train: 100.000%\n",
      "Time elapsed: 1.22 min\n",
      "Epoch: 190/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 190/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 190/200 | Train: 100.000%\n",
      "Time elapsed: 1.23 min\n",
      "Epoch: 191/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 191/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 191/200 | Train: 100.000%\n",
      "Time elapsed: 1.23 min\n",
      "Epoch: 192/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 192/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 192/200 | Train: 100.000%\n",
      "Time elapsed: 1.24 min\n",
      "Epoch: 193/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 193/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 193/200 | Train: 100.000%\n",
      "Time elapsed: 1.25 min\n",
      "Epoch: 194/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 194/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 194/200 | Train: 100.000%\n",
      "Time elapsed: 1.26 min\n",
      "Epoch: 195/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 195/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 195/200 | Train: 100.000%\n",
      "Time elapsed: 1.26 min\n",
      "Epoch: 196/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 196/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 196/200 | Train: 100.000%\n",
      "Time elapsed: 1.27 min\n",
      "Epoch: 197/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 197/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 197/200 | Train: 100.000%\n",
      "Time elapsed: 1.27 min\n",
      "Epoch: 198/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 198/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 198/200 | Train: 100.000%\n",
      "Time elapsed: 1.28 min\n",
      "Epoch: 199/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 199/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 199/200 | Train: 100.000%\n",
      "Time elapsed: 1.29 min\n",
      "Epoch: 200/200 | Batch 0000/0063 | Cost: 0.0000\n",
      "Epoch: 200/200 | Batch 0050/0063 | Cost: 0.0000\n",
      "Epoch: 200/200 | Train: 100.000%\n",
      "Time elapsed: 1.29 min\n",
      "Total Training Time: 1.29 min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, train_loader, device=DEVICE)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba49b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49e6fce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.2.weight', 'classifier.2.bias', 'classifier.4.weight', 'classifier.4.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc3f6eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26630a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 99.81%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edabeee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d493171d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08319991-722f-4267-aae1-89c7a7790a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b1fb5-6e03-491f-8966-d65defc0b8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
